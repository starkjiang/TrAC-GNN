{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starkjiang/TrAC-GNN/blob/main/Homework/module2_gnn_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUl2dG79K5qo"
      },
      "source": [
        "# **Homework for Module 2 of Graph Neural Network**\n",
        "\n",
        "In this Colab, we will implement the GraphSAGE (https://arxiv.org/pdf/1706.02216). Then we will run our model on the PubMed and Cora datasets. They are all standard citation network benchmark datasets (https://arxiv.org/pdf/1603.08861), and are PyG built-in. You can use `torch_geometric.datasets` to check more detail.\n",
        "\n",
        "**Note: Make sure to sequentially run all the cells in each section such that the intermediate variables / packages will carry over to the next cell.**\n",
        "\n",
        "# Device\n",
        "\n",
        "You might want to use GPU for this Colab.\n",
        "\n",
        "Please click on `Runtime` and then `Change runtime type`. Then select the hardware accelerator to **GPU**.\n",
        "\n",
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsnykX5aff_y"
      },
      "outputs": [],
      "source": [
        "\"\"\"Install packages that are required to execute this notebook.\n",
        "\n",
        "\"\"\"\n",
        "# Install packages. This may take some time.\n",
        "!pip install torch-scatter~=2.1.0\n",
        "!pip install torch-sparse~=0.6.16\n",
        "!pip install torch-cluster~=1.6.0\n",
        "!pip install torch-spline-conv~=1.2.1\n",
        "!pip install torch-geometric==2.2.0 -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "\n",
        "# !rm -rf /root/.pyg/Planetoid\n",
        "# !rm -rf /root/.torch_geometric\n",
        "# !rm -rf ./Pubmed\n",
        "\n",
        "# Prevent version incompatability issue.\n",
        "import functools\n",
        "import torch\n",
        "old_load = torch.load\n",
        "torch.load = functools.partial(old_load, weights_only=False)\n",
        "\n",
        "# Set random seed.\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_upv6y5aMZjG"
      },
      "source": [
        "# PubMed Dataset\n",
        "\n",
        "**Question 1:** Please implement to find out the number of graph, the number of nodes, the number of features, and the number of classes associated with this dataset. Please indicate them clearly, not just printing a number (4 points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgKtcNQqgYBS"
      },
      "outputs": [],
      "source": [
        "# Use the PubMed dataset from PyG.\n",
        "from torch_geometric.datasets import Planetoid\n",
        "dataset_pm = Planetoid(root='.', name=\"Pubmed\")\n",
        "\n",
        "data_pm = dataset_pm[0]\n",
        "\n",
        "###############################################################################\n",
        "# TODO: Your code here.\n",
        "# Print the information about the graph here.\n",
        "# Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "###############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHSojU0YOZAW"
      },
      "source": [
        "**Question 2:** Please find out the number of training nodes, the number of evaluation nodes, the number of testing nodes, if there are edges are directed, if the graph as isolated nodes, and if the graph has loops or not (6 points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNIXr2ygNLsE"
      },
      "outputs": [],
      "source": [
        "# Print information about the graph.\n",
        "###############################################################################\n",
        "# TODO: Your code here.\n",
        "# Print the information about the graph here.\n",
        "# Our implementation is ~6 lines, but don't worry if you deviate from this.\n",
        "###############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGqrSspjQkfM"
      },
      "source": [
        "# Neighbor Sampling\n",
        "\n",
        "We use the `NeighborLoader` class to create the batches to get the neighbor sampling. **Please do not modify the default parameters for the grading purpose.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufobRQGgr9u1"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "# Create batches with neighbor sampling.\n",
        "train_loader = NeighborLoader(\n",
        "    data_pm,\n",
        "    num_neighbors=[5, 10],\n",
        "    batch_size=16,\n",
        "    input_nodes=data_pm.train_mask,\n",
        ")\n",
        "\n",
        "# Print each subgraph.\n",
        "for i, subgraph in enumerate(train_loader):\n",
        "    print(f'Subgraph {i}: {subgraph}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFNq4k1usAsC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot each subgraph\n",
        "fig = plt.figure(figsize=(16,16))\n",
        "for idx, (subdata, pos) in enumerate(zip(train_loader, [221, 222, 223, 224])):\n",
        "    G = to_networkx(subdata, to_undirected=True)\n",
        "    ax = fig.add_subplot(pos)\n",
        "    ax.set_title(f'Subgraph {idx}', fontsize=24)\n",
        "    plt.axis('off')\n",
        "    nx.draw_networkx(\n",
        "        G,\n",
        "        pos=nx.spring_layout(G, seed=0),\n",
        "        with_labels=False,\n",
        "        node_color=subdata.y,\n",
        "    )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGQFoyEDRdLU"
      },
      "source": [
        "# GraphSAGE Implementation\n",
        "\n",
        "**Question 3:** In this block, we will establish the `GraphSAGE` module for our model training and testing in the next. We leverage the `SAGEConv` layer to do it. In the `GraphSAGE` module, you need to implement **2** `GraphSAGE` layers with the input/output dimensions and the hidden size. Subsequently, you also need to implement the **forward** function to add nonlinearity into the model. In between 2 `GraphSAGE` layers, we use the **ReLU** activation function and a **Dropout layer** with the rate being **0.5** in this implementation. We also provide the training and testing functions in the same module. **Please do not modify them for grading purposes** (5 points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_Fsfn5tsMi5"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "\n",
        "def accuracy(pred_y, y):\n",
        "    \"\"\"Calculate accuracy.\"\"\"\n",
        "    return ((pred_y == y).sum() / len(y)).item()\n",
        "\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    \"\"\"GraphSAGE.\"\"\"\n",
        "    def __init__(self, dim_in, dim_h, dim_out):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sage1 = None\n",
        "        self.sage2 = None\n",
        "        #######################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Please construct two GraphSAGE layers using SAGEConv.\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate\n",
        "        # from this.\n",
        "        #######################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        #######################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Please implement the forward function based on the requirements. Also,\n",
        "        # modify the return to reflect on your implementation.\n",
        "        # Our implementation is ~3 lines, but don't worry if you deviate\n",
        "        # from this.\n",
        "        #######################################################################\n",
        "\n",
        "        return x\n",
        "\n",
        "    def fit(self, loader, epochs):\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "\n",
        "        self.train()\n",
        "        for epoch in range(epochs+1):\n",
        "            total_loss = 0\n",
        "            acc = 0\n",
        "            val_loss = 0\n",
        "            val_acc = 0\n",
        "\n",
        "            # Train on batches.\n",
        "            for batch in loader:\n",
        "                optimizer.zero_grad()\n",
        "                out = self(batch.x, batch.edge_index)\n",
        "                loss = criterion(\n",
        "                    out[batch.train_mask],\n",
        "                    batch.y[batch.train_mask]\n",
        "                )\n",
        "                total_loss += loss.item()\n",
        "                acc += accuracy(\n",
        "                    out[batch.train_mask].argmax(dim=1),\n",
        "                    batch.y[batch.train_mask]\n",
        "                )\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Validation.\n",
        "                val_loss += criterion(\n",
        "                    out[batch.val_mask],\n",
        "                    batch.y[batch.val_mask]\n",
        "                )\n",
        "                val_acc += accuracy(\n",
        "                    out[batch.val_mask].argmax(dim=1),\n",
        "                    batch.y[batch.val_mask]\n",
        "                )\n",
        "\n",
        "            # Print metrics every 10 epochs.\n",
        "            if epoch % 20 == 0:\n",
        "                print(f'Epoch {epoch:>3} | Train Loss: {loss/len(loader):.3f} '\n",
        "                      f'| Train Acc: {acc/len(loader)*100:>6.2f}% '\n",
        "                      f'| Val Loss: {val_loss/len(loader):.2f} '\n",
        "                      f'| Val Acc: {val_acc/len(loader)*100:.2f}%'\n",
        "                     )\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test(self, data):\n",
        "        self.eval()\n",
        "        out = self(data.x, data.edge_index)\n",
        "        acc = accuracy(\n",
        "            out.argmax(dim=1)[data.test_mask],\n",
        "            data.y[data.test_mask]\n",
        "        )\n",
        "        return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK9PfvCmWjoc"
      },
      "source": [
        "**Question 4**: What is the maximum accuracy for the testing set by using GraphSAGE? (5 points)\n",
        "\n",
        "Please feel free to play with the hyperparameters to get your value. Also, please make sure you will run the cell and then get the same accuracy value as you report. If the two values are different, you will lose the point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_F9hD4lsvln"
      },
      "outputs": [],
      "source": [
        "# Create GraphSAGE.\n",
        "graphsage = GraphSAGE(dataset_pm.num_features, 32, dataset_pm.num_classes)\n",
        "print(graphsage)\n",
        "\n",
        "# Train.\n",
        "graphsage.fit(train_loader, 100)\n",
        "\n",
        "# Test.\n",
        "acc = graphsage.test(data_pm)\n",
        "print(f'GraphSAGE test accuracy: {acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlKJGEUrv1Pw"
      },
      "source": [
        "# Cora Dataset\n",
        "\n",
        "**Question 5:** Please use another dataset - Cora to train and test a different model. Cora dataset is also a standard citation network benchmark dataset. **Please follow the similar steps as the above to report your best testing accuracy.** You also need to print the information about the graph and show the neighbor sampling (10 points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxdaDXpls3sg"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# TODO: Your code is here!\n",
        "# Please import the Cora data from PyG and show the similar steps to report the\n",
        "# information of the graph. Then, please implement the neighbor sampling. Call\n",
        "# the GraphSAGE model you have implemented and then train and test the model\n",
        "# with the dataset.\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igxFAsdJ2SJX"
      },
      "source": [
        "# Submission\n",
        "\n",
        "To receive points, you must answer all the questions listed above. Please ensure that the output of each code cell is visible in your submitted `.ipynb` file. When submitting, run the notebook in your own Colab account and share the link. For grading, the outputs of specific cells will be checked. If you prefer to run the notebook locally on your machine, upload the completed notebook to your Colab account and share the link. In case of technical issues, you may also email me your file directly. Please name the file in the format like ` Name_module2_gnn_homework.ipynb`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2e83Phgmlz8lMfNC4rPGO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}