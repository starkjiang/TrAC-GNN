{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpzpthTGQTflZ7C+CgAOeL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starkjiang/TrAC-GNN/blob/main/basic_gnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages"
      ],
      "metadata": {
        "id": "UR2T-nYcubMU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RX1rz8zAOMj"
      },
      "outputs": [],
      "source": [
        "\"\"\"Install packages that are required to execute this notebook.\n",
        "\"\"\"\n",
        "# Install packages. This may take some time.\n",
        "!pip install torch-scatter~=2.1.0\n",
        "!pip install torch-sparse~=0.6.16\n",
        "!pip install torch-cluster~=1.6.0\n",
        "!pip install torch-spline-conv~=1.2.1\n",
        "!pip install torch-geometric==2.2.0 -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Function for Visualization"
      ],
      "metadata": {
        "id": "41B31YePAv4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "def visualize(h, color):\n",
        "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2ffLhQipAmre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Citeseer Dataset"
      ],
      "metadata": {
        "id": "Yl0VU1mDufP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the built-in dataset from PyG.\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "# Import dataset from PyTorch Geometric\n",
        "dataset = Planetoid(root=\".\", name=\"CiteSeer\")\n",
        "\n",
        "data = dataset[0]\n",
        "\n",
        "# Print information about the dataset\n",
        "print(f'Dataset: {dataset}')\n",
        "print('---------------')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "\n",
        "# Print information about the graph\n",
        "print(f'\\nGraph:')\n",
        "print('------')\n",
        "print(f'Edges are directed: {data.is_directed()}')\n",
        "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Graph has loops: {data.has_self_loops()}')"
      ],
      "metadata": {
        "id": "uIjtG7OCSm5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataframe of Citeseer"
      ],
      "metadata": {
        "id": "q7teRAz9u4Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use CiteSeer dataset from the built-in datasets.\n",
        "import pandas as pd\n",
        "\n",
        "dataset = Planetoid(root=\".\", name=\"CiteSeer\")\n",
        "data = dataset[0]\n",
        "\n",
        "df_x = pd.DataFrame(data.x.numpy())\n",
        "df_x['label'] = pd.DataFrame(data.y)\n",
        "df_x"
      ],
      "metadata": {
        "id": "0eYp6Ff1TOAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP as baseline\n",
        "\n",
        "We use Multi-layer Perceptron as a baseline model for comparison. Please construct a single hidden layer MLP in the following and train the model."
      ],
      "metadata": {
        "id": "NloyoKiYvBGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct an vanilla MLP for classification.\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "    \"\"\"Calculate accuracy.\"\"\"\n",
        "    return torch.sum(y_pred == y_true) / len(y_true)\n",
        "\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    \"\"\"Multilayer Perceptron\"\"\"\n",
        "    def __init__(self, dim_in, dim_h, dim_out):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize the linear layers\n",
        "        self.linear1 = None\n",
        "        self.linear2 = None\n",
        "\n",
        "        # TODO: Define two linear layers\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the two linear layers.\n",
        "        # TODO: Use relu activation (F.relu) to add nonlinearity\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def fit(self, data, epochs):\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.parameters(),\n",
        "                                          lr=0.01,\n",
        "                                          weight_decay=5e-4)\n",
        "\n",
        "        self.train()\n",
        "        for epoch in range(epochs+1):\n",
        "            optimizer.zero_grad()\n",
        "            out = self(data.x)\n",
        "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
        "                          data.y[data.train_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if(epoch % 20 == 0):\n",
        "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "                val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
        "                                   data.y[data.val_mask])\n",
        "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
        "                      f' {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | '\n",
        "                      f'Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test(self, data):\n",
        "        self.eval()\n",
        "        out = self(data.x)\n",
        "        acc = accuracy(\n",
        "            out.argmax(dim=1)[data.test_mask], data.y[data.test_mask]\n",
        "        )\n",
        "        return acc\n",
        "\n",
        "# Create MLP model\n",
        "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
        "print(mlp)\n",
        "\n",
        "# Train\n",
        "mlp.fit(data, epochs=200)\n",
        "\n",
        "# Test\n",
        "acc = mlp.test(data)\n",
        "print(f'\\nMLP test accuracy: {acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "o5Eit9moTQcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a vanilla GNN layer"
      ],
      "metadata": {
        "id": "o8QvGLLWvFtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a basic GNN layer.\n",
        "class VanillaGNNLayer(torch.nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.linear = Linear(dim_in, dim_out, bias=False)\n",
        "\n",
        "    def forward(self, x, adjacency):\n",
        "        # Neighborhood aggregation through matrix multiplication.\n",
        "        # TODO: Call the torch.sparese.mm() to calculate.\n",
        "        return x"
      ],
      "metadata": {
        "id": "N0SmrKmCTx-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the adjacency matrix"
      ],
      "metadata": {
        "id": "uZbmYnc6vMZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the input graph through adjacency.\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "adjacency = to_dense_adj(data.edge_index)[0]\n",
        "adjacency += torch.eye(len(adjacency)) # We need to include self-loops.\n",
        "adjacency"
      ],
      "metadata": {
        "id": "mYUo6H8fT6GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create basic GNN model\n",
        "\n",
        "**Exercise:**\n",
        "\n",
        "1. Define two GNN layers in the `VanillaGNN` model\n",
        "2. Establish the whole basic GNN model by leveraging the GNN layers"
      ],
      "metadata": {
        "id": "qVe0qoyVvRVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create basic GNN model and then train and test the data.\n",
        "class VanillaGNN(torch.nn.Module):\n",
        "    \"\"\"Vanilla Graph Neural Network\"\"\"\n",
        "    def __init__(self, dim_in, dim_h, dim_out):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize two GNN layers.\n",
        "        self.gnn1 = None\n",
        "        self.gnn2 = None\n",
        "\n",
        "        # TODO: Create two basic GNN layers through the basic class\n",
        "        # VanillaGNNLayer.\n",
        "\n",
        "\n",
        "    def forward(self, x, adjacency):\n",
        "        # Pass the input through the two GNN layers.\n",
        "        # TODO: Follow similarly MLP, define the forward function here for GNN.\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def fit(self, data, epochs):\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.parameters(),\n",
        "                                      lr=0.01,\n",
        "                                      weight_decay=5e-4)\n",
        "\n",
        "        self.train()\n",
        "        for epoch in range(epochs+1):\n",
        "            optimizer.zero_grad()\n",
        "            out = self(data.x, adjacency)\n",
        "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
        "                          data.y[data.train_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if(epoch % 20 == 0):\n",
        "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "                val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
        "                                  data.y[data.val_mask])\n",
        "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
        "                      f' {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | '\n",
        "                      f'Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test(self, data):\n",
        "        self.eval()\n",
        "        out = self(data.x, adjacency)\n",
        "        acc = accuracy(\n",
        "            out.argmax(dim=1)[data.test_mask], data.y[data.test_mask]\n",
        "        )\n",
        "        return acc"
      ],
      "metadata": {
        "id": "WAytaGwAT-oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creat Basic GNN and Visualize Node Embeddings\n",
        "\n",
        "We compare the node embeddings from both untrained and trained models."
      ],
      "metadata": {
        "id": "hSZB1up-Bf0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Vanilla GNN model\n",
        "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
        "print(gnn)\n",
        "\n",
        "out = gnn(data.x, adjacency)\n",
        "\n",
        "# Visualize the node embedding of untrained GNN.\n",
        "visualize(out, color=data.y)\n",
        "\n",
        "# Train.\n",
        "gnn.fit(data, epochs=200)\n",
        "\n",
        "# Test.\n",
        "acc = gnn.test(data)\n",
        "print(f'\\nGNN test accuracy: {acc*100:.2f}%')\n",
        "\n",
        "# Visualize the output embeddings of the trained model.\n",
        "out = gnn(data.x, adjacency)\n",
        "visualize(out, color=data.y)"
      ],
      "metadata": {
        "id": "0BWD4yeJBfAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Facebook Page-Page Dataset"
      ],
      "metadata": {
        "id": "t3xfq076BLqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import FacebookPagePage\n",
        "\n",
        "# Import dataset from PyTorch Geometric\n",
        "dataset = FacebookPagePage(root=\".\")\n",
        "\n",
        "data = dataset[0]\n",
        "\n",
        "# Print information about the dataset\n",
        "print(f'Dataset: {dataset}')\n",
        "print('-----------------------')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of nodes: {data.x.shape[0]}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "# Print information about the graph\n",
        "print(f'\\nGraph:')\n",
        "print('------')\n",
        "print(f'Edges are directed: {data.is_directed()}')\n",
        "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Graph has loops: {data.has_self_loops()}')"
      ],
      "metadata": {
        "id": "3iZbz-73BFs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Facebook Page-Page dataset for training and testing"
      ],
      "metadata": {
        "id": "3_L939fqvWnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Facebook Page-Page dataset.\n",
        "dataset = FacebookPagePage(root=\".\")\n",
        "data = dataset[0]\n",
        "data.train_mask = range(18000)\n",
        "data.val_mask = range(18001, 20000)\n",
        "data.test_mask = range(20001, 22470)\n",
        "\n",
        "# Adjacency matrix\n",
        "adjacency = to_dense_adj(data.edge_index)[0]\n",
        "adjacency += torch.eye(len(adjacency))\n",
        "adjacency\n",
        "\n",
        "# Use MLP for classification.\n",
        "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
        "print(mlp)\n",
        "mlp.fit(data, epochs=100)\n",
        "acc = mlp.test(data)\n",
        "print(f'\\nMLP test accuracy: {acc*100:.2f}%\\n')\n",
        "\n",
        "# Use GNN for classification.\n",
        "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
        "print(gnn)\n",
        "gnn.fit(data, epochs=100)\n",
        "acc = gnn.test(data)\n",
        "print(f'\\nGNN test accuracy: {acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "Ib5VvTxcVFSZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}