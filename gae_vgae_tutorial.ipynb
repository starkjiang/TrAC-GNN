{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJHOWxiQciqj+mkaj8Jcgz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starkjiang/TrAC-GNN/blob/main/gae_vgae_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAE - VGAE Tutorial\n",
        "\n",
        "In this tutorial, we will learn how to implement graph Autoencoder (GAE) and variational graph Autoencoder (VGAE) for the link prediction in a graph.\n",
        "\n",
        "# 1. Installation"
      ],
      "metadata": {
        "id": "53wUvRWg1iRx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVQ3WOTZ1euA",
        "outputId": "eeab8827-bc26-4675-cce1-3624ae9b8c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m102.4/108.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "8QUBHv8q3kuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Implementation\n",
        "\n",
        "We still use CORA dataset in this tutorial."
      ],
      "metadata": {
        "id": "ZPZMa6qF3uXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "import time\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GAE, VGAE, GCNConv\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--variational', action='store_true')\n",
        "parser.add_argument('--linear', action='store_true')\n",
        "parser.add_argument('--dataset', type=str, default='Cora',\n",
        "                    choices=['Cora', 'CiteSeer', 'PubMed'])\n",
        "parser.add_argument('--epochs', type=int, default=400)\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.NormalizeFeatures(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
        "                      split_labels=True, add_negative_train_samples=False),\n",
        "])\n",
        "dataset = Planetoid('.', name='Cora', transform=transform)\n",
        "train_data, val_data, test_data = dataset[0]\n",
        "\n",
        "\n",
        "# Define the encoder for GAE with GCN layer.\n",
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "# Define the encoder for VGAE with GCN layer.\n",
        "class VariationalGCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
        "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
        "\n",
        "# Define the encoder for GAE with linear layer.\n",
        "class LinearEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.conv(x, edge_index)\n",
        "\n",
        "# Define the encoder for VGAE with linear layer.\n",
        "class VariationalLinearEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv_mu = GCNConv(in_channels, out_channels)\n",
        "        self.conv_logstd = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
        "\n",
        "\n",
        "in_channels, out_channels = dataset.num_features, 16\n",
        "\n",
        "if not args.variational and not args.linear:\n",
        "    model = GAE(GCNEncoder(in_channels, out_channels))\n",
        "elif not args.variational and args.linear:\n",
        "    model = GAE(LinearEncoder(in_channels, out_channels))\n",
        "elif args.variational and not args.linear:\n",
        "    model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n",
        "elif args.variational and args.linear:\n",
        "    model = VGAE(VariationalLinearEncoder(in_channels, out_channels))\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x, train_data.edge_index)\n",
        "    loss = model.recon_loss(z, train_data.pos_edge_label_index)\n",
        "    if args.variational:\n",
        "        loss = loss + (1 / train_data.num_nodes) * model.kl_loss()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)\n",
        "\n",
        "\n",
        "times = []\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    start = time.time()\n",
        "    loss = train()\n",
        "    auc, ap = test(test_data)\n",
        "    print(f'Epoch: {epoch:03d}, AUC: {auc:.4f}, AP: {ap:.4f}')\n",
        "    times.append(time.time() - start)\n",
        "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxKE11G5_M1F",
        "outputId": "367849f3-0473-4f7a-e7b2-c276198b68e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, AUC: 0.6868, AP: 0.7155\n",
            "Epoch: 002, AUC: 0.6831, AP: 0.7128\n",
            "Epoch: 003, AUC: 0.6816, AP: 0.7122\n",
            "Epoch: 004, AUC: 0.6812, AP: 0.7128\n",
            "Epoch: 005, AUC: 0.6826, AP: 0.7146\n",
            "Epoch: 006, AUC: 0.6839, AP: 0.7175\n",
            "Epoch: 007, AUC: 0.6843, AP: 0.7195\n",
            "Epoch: 008, AUC: 0.6839, AP: 0.7206\n",
            "Epoch: 009, AUC: 0.6836, AP: 0.7210\n",
            "Epoch: 010, AUC: 0.6826, AP: 0.7205\n",
            "Epoch: 011, AUC: 0.6816, AP: 0.7197\n",
            "Epoch: 012, AUC: 0.6810, AP: 0.7202\n",
            "Epoch: 013, AUC: 0.6809, AP: 0.7208\n",
            "Epoch: 014, AUC: 0.6829, AP: 0.7228\n",
            "Epoch: 015, AUC: 0.6872, AP: 0.7244\n",
            "Epoch: 016, AUC: 0.6931, AP: 0.7268\n",
            "Epoch: 017, AUC: 0.6948, AP: 0.7264\n",
            "Epoch: 018, AUC: 0.6945, AP: 0.7258\n",
            "Epoch: 019, AUC: 0.6943, AP: 0.7250\n",
            "Epoch: 020, AUC: 0.6985, AP: 0.7264\n",
            "Epoch: 021, AUC: 0.7135, AP: 0.7331\n",
            "Epoch: 022, AUC: 0.7384, AP: 0.7474\n",
            "Epoch: 023, AUC: 0.7591, AP: 0.7624\n",
            "Epoch: 024, AUC: 0.7702, AP: 0.7713\n",
            "Epoch: 025, AUC: 0.7747, AP: 0.7748\n",
            "Epoch: 026, AUC: 0.7779, AP: 0.7771\n",
            "Epoch: 027, AUC: 0.7832, AP: 0.7821\n",
            "Epoch: 028, AUC: 0.7904, AP: 0.7894\n",
            "Epoch: 029, AUC: 0.7942, AP: 0.7930\n",
            "Epoch: 030, AUC: 0.7953, AP: 0.7932\n",
            "Epoch: 031, AUC: 0.7962, AP: 0.7938\n",
            "Epoch: 032, AUC: 0.7963, AP: 0.7931\n",
            "Epoch: 033, AUC: 0.7993, AP: 0.7955\n",
            "Epoch: 034, AUC: 0.8028, AP: 0.7984\n",
            "Epoch: 035, AUC: 0.8075, AP: 0.8024\n",
            "Epoch: 036, AUC: 0.8135, AP: 0.8078\n",
            "Epoch: 037, AUC: 0.8207, AP: 0.8149\n",
            "Epoch: 038, AUC: 0.8273, AP: 0.8208\n",
            "Epoch: 039, AUC: 0.8333, AP: 0.8265\n",
            "Epoch: 040, AUC: 0.8385, AP: 0.8318\n",
            "Epoch: 041, AUC: 0.8418, AP: 0.8348\n",
            "Epoch: 042, AUC: 0.8454, AP: 0.8377\n",
            "Epoch: 043, AUC: 0.8475, AP: 0.8392\n",
            "Epoch: 044, AUC: 0.8469, AP: 0.8386\n",
            "Epoch: 045, AUC: 0.8478, AP: 0.8397\n",
            "Epoch: 046, AUC: 0.8492, AP: 0.8414\n",
            "Epoch: 047, AUC: 0.8501, AP: 0.8431\n",
            "Epoch: 048, AUC: 0.8508, AP: 0.8446\n",
            "Epoch: 049, AUC: 0.8534, AP: 0.8490\n",
            "Epoch: 050, AUC: 0.8542, AP: 0.8512\n",
            "Epoch: 051, AUC: 0.8530, AP: 0.8508\n",
            "Epoch: 052, AUC: 0.8525, AP: 0.8514\n",
            "Epoch: 053, AUC: 0.8574, AP: 0.8576\n",
            "Epoch: 054, AUC: 0.8616, AP: 0.8622\n",
            "Epoch: 055, AUC: 0.8632, AP: 0.8650\n",
            "Epoch: 056, AUC: 0.8624, AP: 0.8654\n",
            "Epoch: 057, AUC: 0.8628, AP: 0.8663\n",
            "Epoch: 058, AUC: 0.8672, AP: 0.8701\n",
            "Epoch: 059, AUC: 0.8715, AP: 0.8725\n",
            "Epoch: 060, AUC: 0.8741, AP: 0.8734\n",
            "Epoch: 061, AUC: 0.8762, AP: 0.8741\n",
            "Epoch: 062, AUC: 0.8776, AP: 0.8751\n",
            "Epoch: 063, AUC: 0.8797, AP: 0.8772\n",
            "Epoch: 064, AUC: 0.8812, AP: 0.8785\n",
            "Epoch: 065, AUC: 0.8832, AP: 0.8794\n",
            "Epoch: 066, AUC: 0.8842, AP: 0.8795\n",
            "Epoch: 067, AUC: 0.8858, AP: 0.8810\n",
            "Epoch: 068, AUC: 0.8869, AP: 0.8823\n",
            "Epoch: 069, AUC: 0.8877, AP: 0.8825\n",
            "Epoch: 070, AUC: 0.8875, AP: 0.8822\n",
            "Epoch: 071, AUC: 0.8870, AP: 0.8829\n",
            "Epoch: 072, AUC: 0.8860, AP: 0.8815\n",
            "Epoch: 073, AUC: 0.8869, AP: 0.8830\n",
            "Epoch: 074, AUC: 0.8883, AP: 0.8852\n",
            "Epoch: 075, AUC: 0.8887, AP: 0.8865\n",
            "Epoch: 076, AUC: 0.8887, AP: 0.8869\n",
            "Epoch: 077, AUC: 0.8881, AP: 0.8866\n",
            "Epoch: 078, AUC: 0.8870, AP: 0.8851\n",
            "Epoch: 079, AUC: 0.8871, AP: 0.8855\n",
            "Epoch: 080, AUC: 0.8880, AP: 0.8873\n",
            "Epoch: 081, AUC: 0.8893, AP: 0.8885\n",
            "Epoch: 082, AUC: 0.8901, AP: 0.8893\n",
            "Epoch: 083, AUC: 0.8897, AP: 0.8887\n",
            "Epoch: 084, AUC: 0.8891, AP: 0.8878\n",
            "Epoch: 085, AUC: 0.8887, AP: 0.8875\n",
            "Epoch: 086, AUC: 0.8896, AP: 0.8884\n",
            "Epoch: 087, AUC: 0.8907, AP: 0.8896\n",
            "Epoch: 088, AUC: 0.8920, AP: 0.8914\n",
            "Epoch: 089, AUC: 0.8933, AP: 0.8927\n",
            "Epoch: 090, AUC: 0.8944, AP: 0.8934\n",
            "Epoch: 091, AUC: 0.8958, AP: 0.8946\n",
            "Epoch: 092, AUC: 0.8967, AP: 0.8947\n",
            "Epoch: 093, AUC: 0.8981, AP: 0.8955\n",
            "Epoch: 094, AUC: 0.8997, AP: 0.8973\n",
            "Epoch: 095, AUC: 0.9012, AP: 0.8991\n",
            "Epoch: 096, AUC: 0.9027, AP: 0.9005\n",
            "Epoch: 097, AUC: 0.9036, AP: 0.9009\n",
            "Epoch: 098, AUC: 0.9040, AP: 0.9001\n",
            "Epoch: 099, AUC: 0.9048, AP: 0.9003\n",
            "Epoch: 100, AUC: 0.9054, AP: 0.9010\n",
            "Epoch: 101, AUC: 0.9058, AP: 0.9019\n",
            "Epoch: 102, AUC: 0.9066, AP: 0.9030\n",
            "Epoch: 103, AUC: 0.9063, AP: 0.9027\n",
            "Epoch: 104, AUC: 0.9061, AP: 0.9021\n",
            "Epoch: 105, AUC: 0.9071, AP: 0.9018\n",
            "Epoch: 106, AUC: 0.9084, AP: 0.9029\n",
            "Epoch: 107, AUC: 0.9089, AP: 0.9037\n",
            "Epoch: 108, AUC: 0.9084, AP: 0.9036\n",
            "Epoch: 109, AUC: 0.9078, AP: 0.9034\n",
            "Epoch: 110, AUC: 0.9063, AP: 0.9020\n",
            "Epoch: 111, AUC: 0.9058, AP: 0.9013\n",
            "Epoch: 112, AUC: 0.9065, AP: 0.9023\n",
            "Epoch: 113, AUC: 0.9068, AP: 0.9033\n",
            "Epoch: 114, AUC: 0.9086, AP: 0.9040\n",
            "Epoch: 115, AUC: 0.9089, AP: 0.9034\n",
            "Epoch: 116, AUC: 0.9080, AP: 0.9024\n",
            "Epoch: 117, AUC: 0.9070, AP: 0.9020\n",
            "Epoch: 118, AUC: 0.9056, AP: 0.9022\n",
            "Epoch: 119, AUC: 0.9057, AP: 0.9024\n",
            "Epoch: 120, AUC: 0.9067, AP: 0.9028\n",
            "Epoch: 121, AUC: 0.9073, AP: 0.9027\n",
            "Epoch: 122, AUC: 0.9080, AP: 0.9027\n",
            "Epoch: 123, AUC: 0.9081, AP: 0.9029\n",
            "Epoch: 124, AUC: 0.9083, AP: 0.9040\n",
            "Epoch: 125, AUC: 0.9079, AP: 0.9038\n",
            "Epoch: 126, AUC: 0.9072, AP: 0.9035\n",
            "Epoch: 127, AUC: 0.9073, AP: 0.9033\n",
            "Epoch: 128, AUC: 0.9078, AP: 0.9030\n",
            "Epoch: 129, AUC: 0.9089, AP: 0.9037\n",
            "Epoch: 130, AUC: 0.9097, AP: 0.9054\n",
            "Epoch: 131, AUC: 0.9091, AP: 0.9057\n",
            "Epoch: 132, AUC: 0.9083, AP: 0.9057\n",
            "Epoch: 133, AUC: 0.9079, AP: 0.9056\n",
            "Epoch: 134, AUC: 0.9076, AP: 0.9050\n",
            "Epoch: 135, AUC: 0.9079, AP: 0.9046\n",
            "Epoch: 136, AUC: 0.9092, AP: 0.9057\n",
            "Epoch: 137, AUC: 0.9100, AP: 0.9069\n",
            "Epoch: 138, AUC: 0.9101, AP: 0.9079\n",
            "Epoch: 139, AUC: 0.9097, AP: 0.9084\n",
            "Epoch: 140, AUC: 0.9079, AP: 0.9071\n",
            "Epoch: 141, AUC: 0.9060, AP: 0.9048\n",
            "Epoch: 142, AUC: 0.9068, AP: 0.9053\n",
            "Epoch: 143, AUC: 0.9086, AP: 0.9073\n",
            "Epoch: 144, AUC: 0.9092, AP: 0.9081\n",
            "Epoch: 145, AUC: 0.9091, AP: 0.9084\n",
            "Epoch: 146, AUC: 0.9078, AP: 0.9077\n",
            "Epoch: 147, AUC: 0.9062, AP: 0.9062\n",
            "Epoch: 148, AUC: 0.9054, AP: 0.9054\n",
            "Epoch: 149, AUC: 0.9063, AP: 0.9063\n",
            "Epoch: 150, AUC: 0.9068, AP: 0.9068\n",
            "Epoch: 151, AUC: 0.9073, AP: 0.9071\n",
            "Epoch: 152, AUC: 0.9076, AP: 0.9070\n",
            "Epoch: 153, AUC: 0.9068, AP: 0.9061\n",
            "Epoch: 154, AUC: 0.9051, AP: 0.9043\n",
            "Epoch: 155, AUC: 0.9051, AP: 0.9046\n",
            "Epoch: 156, AUC: 0.9065, AP: 0.9064\n",
            "Epoch: 157, AUC: 0.9076, AP: 0.9072\n",
            "Epoch: 158, AUC: 0.9080, AP: 0.9077\n",
            "Epoch: 159, AUC: 0.9078, AP: 0.9070\n",
            "Epoch: 160, AUC: 0.9066, AP: 0.9060\n",
            "Epoch: 161, AUC: 0.9062, AP: 0.9059\n",
            "Epoch: 162, AUC: 0.9066, AP: 0.9073\n",
            "Epoch: 163, AUC: 0.9070, AP: 0.9077\n",
            "Epoch: 164, AUC: 0.9078, AP: 0.9079\n",
            "Epoch: 165, AUC: 0.9080, AP: 0.9078\n",
            "Epoch: 166, AUC: 0.9074, AP: 0.9069\n",
            "Epoch: 167, AUC: 0.9062, AP: 0.9057\n",
            "Epoch: 168, AUC: 0.9058, AP: 0.9066\n",
            "Epoch: 169, AUC: 0.9063, AP: 0.9077\n",
            "Epoch: 170, AUC: 0.9072, AP: 0.9080\n",
            "Epoch: 171, AUC: 0.9071, AP: 0.9072\n",
            "Epoch: 172, AUC: 0.9067, AP: 0.9070\n",
            "Epoch: 173, AUC: 0.9059, AP: 0.9075\n",
            "Epoch: 174, AUC: 0.9048, AP: 0.9073\n",
            "Epoch: 175, AUC: 0.9046, AP: 0.9066\n",
            "Epoch: 176, AUC: 0.9056, AP: 0.9062\n",
            "Epoch: 177, AUC: 0.9058, AP: 0.9054\n",
            "Epoch: 178, AUC: 0.9057, AP: 0.9050\n",
            "Epoch: 179, AUC: 0.9056, AP: 0.9065\n",
            "Epoch: 180, AUC: 0.9047, AP: 0.9072\n",
            "Epoch: 181, AUC: 0.9044, AP: 0.9069\n",
            "Epoch: 182, AUC: 0.9051, AP: 0.9065\n",
            "Epoch: 183, AUC: 0.9054, AP: 0.9054\n",
            "Epoch: 184, AUC: 0.9061, AP: 0.9052\n",
            "Epoch: 185, AUC: 0.9058, AP: 0.9065\n",
            "Epoch: 186, AUC: 0.9052, AP: 0.9074\n",
            "Epoch: 187, AUC: 0.9047, AP: 0.9074\n",
            "Epoch: 188, AUC: 0.9049, AP: 0.9071\n",
            "Epoch: 189, AUC: 0.9054, AP: 0.9065\n",
            "Epoch: 190, AUC: 0.9052, AP: 0.9057\n",
            "Epoch: 191, AUC: 0.9047, AP: 0.9055\n",
            "Epoch: 192, AUC: 0.9041, AP: 0.9058\n",
            "Epoch: 193, AUC: 0.9046, AP: 0.9072\n",
            "Epoch: 194, AUC: 0.9046, AP: 0.9073\n",
            "Epoch: 195, AUC: 0.9051, AP: 0.9070\n",
            "Epoch: 196, AUC: 0.9056, AP: 0.9071\n",
            "Epoch: 197, AUC: 0.9057, AP: 0.9069\n",
            "Epoch: 198, AUC: 0.9049, AP: 0.9063\n",
            "Epoch: 199, AUC: 0.9047, AP: 0.9071\n",
            "Epoch: 200, AUC: 0.9043, AP: 0.9070\n",
            "Epoch: 201, AUC: 0.9045, AP: 0.9067\n",
            "Epoch: 202, AUC: 0.9056, AP: 0.9069\n",
            "Epoch: 203, AUC: 0.9058, AP: 0.9063\n",
            "Epoch: 204, AUC: 0.9051, AP: 0.9045\n",
            "Epoch: 205, AUC: 0.9049, AP: 0.9047\n",
            "Epoch: 206, AUC: 0.9050, AP: 0.9057\n",
            "Epoch: 207, AUC: 0.9052, AP: 0.9071\n",
            "Epoch: 208, AUC: 0.9055, AP: 0.9078\n",
            "Epoch: 209, AUC: 0.9050, AP: 0.9065\n",
            "Epoch: 210, AUC: 0.9041, AP: 0.9044\n",
            "Epoch: 211, AUC: 0.9037, AP: 0.9034\n",
            "Epoch: 212, AUC: 0.9046, AP: 0.9048\n",
            "Epoch: 213, AUC: 0.9049, AP: 0.9065\n",
            "Epoch: 214, AUC: 0.9046, AP: 0.9068\n",
            "Epoch: 215, AUC: 0.9040, AP: 0.9063\n",
            "Epoch: 216, AUC: 0.9038, AP: 0.9056\n",
            "Epoch: 217, AUC: 0.9040, AP: 0.9049\n",
            "Epoch: 218, AUC: 0.9041, AP: 0.9049\n",
            "Epoch: 219, AUC: 0.9043, AP: 0.9060\n",
            "Epoch: 220, AUC: 0.9044, AP: 0.9073\n",
            "Epoch: 221, AUC: 0.9042, AP: 0.9074\n",
            "Epoch: 222, AUC: 0.9042, AP: 0.9069\n",
            "Epoch: 223, AUC: 0.9044, AP: 0.9057\n",
            "Epoch: 224, AUC: 0.9040, AP: 0.9042\n",
            "Epoch: 225, AUC: 0.9045, AP: 0.9052\n",
            "Epoch: 226, AUC: 0.9048, AP: 0.9065\n",
            "Epoch: 227, AUC: 0.9053, AP: 0.9075\n",
            "Epoch: 228, AUC: 0.9053, AP: 0.9074\n",
            "Epoch: 229, AUC: 0.9055, AP: 0.9078\n",
            "Epoch: 230, AUC: 0.9057, AP: 0.9075\n",
            "Epoch: 231, AUC: 0.9059, AP: 0.9074\n",
            "Epoch: 232, AUC: 0.9059, AP: 0.9074\n",
            "Epoch: 233, AUC: 0.9054, AP: 0.9071\n",
            "Epoch: 234, AUC: 0.9061, AP: 0.9080\n",
            "Epoch: 235, AUC: 0.9065, AP: 0.9081\n",
            "Epoch: 236, AUC: 0.9064, AP: 0.9077\n",
            "Epoch: 237, AUC: 0.9068, AP: 0.9083\n",
            "Epoch: 238, AUC: 0.9070, AP: 0.9086\n",
            "Epoch: 239, AUC: 0.9067, AP: 0.9081\n",
            "Epoch: 240, AUC: 0.9062, AP: 0.9078\n",
            "Epoch: 241, AUC: 0.9060, AP: 0.9078\n",
            "Epoch: 242, AUC: 0.9058, AP: 0.9081\n",
            "Epoch: 243, AUC: 0.9066, AP: 0.9091\n",
            "Epoch: 244, AUC: 0.9077, AP: 0.9101\n",
            "Epoch: 245, AUC: 0.9076, AP: 0.9091\n",
            "Epoch: 246, AUC: 0.9070, AP: 0.9078\n",
            "Epoch: 247, AUC: 0.9063, AP: 0.9073\n",
            "Epoch: 248, AUC: 0.9067, AP: 0.9088\n",
            "Epoch: 249, AUC: 0.9066, AP: 0.9096\n",
            "Epoch: 250, AUC: 0.9065, AP: 0.9099\n",
            "Epoch: 251, AUC: 0.9070, AP: 0.9096\n",
            "Epoch: 252, AUC: 0.9071, AP: 0.9090\n",
            "Epoch: 253, AUC: 0.9069, AP: 0.9094\n",
            "Epoch: 254, AUC: 0.9058, AP: 0.9087\n",
            "Epoch: 255, AUC: 0.9053, AP: 0.9088\n",
            "Epoch: 256, AUC: 0.9056, AP: 0.9093\n",
            "Epoch: 257, AUC: 0.9068, AP: 0.9103\n",
            "Epoch: 258, AUC: 0.9070, AP: 0.9096\n",
            "Epoch: 259, AUC: 0.9067, AP: 0.9093\n",
            "Epoch: 260, AUC: 0.9064, AP: 0.9094\n",
            "Epoch: 261, AUC: 0.9054, AP: 0.9085\n",
            "Epoch: 262, AUC: 0.9056, AP: 0.9085\n",
            "Epoch: 263, AUC: 0.9063, AP: 0.9090\n",
            "Epoch: 264, AUC: 0.9074, AP: 0.9100\n",
            "Epoch: 265, AUC: 0.9078, AP: 0.9109\n",
            "Epoch: 266, AUC: 0.9075, AP: 0.9109\n",
            "Epoch: 267, AUC: 0.9068, AP: 0.9101\n",
            "Epoch: 268, AUC: 0.9060, AP: 0.9091\n",
            "Epoch: 269, AUC: 0.9054, AP: 0.9082\n",
            "Epoch: 270, AUC: 0.9059, AP: 0.9081\n",
            "Epoch: 271, AUC: 0.9070, AP: 0.9099\n",
            "Epoch: 272, AUC: 0.9077, AP: 0.9111\n",
            "Epoch: 273, AUC: 0.9075, AP: 0.9108\n",
            "Epoch: 274, AUC: 0.9076, AP: 0.9107\n",
            "Epoch: 275, AUC: 0.9084, AP: 0.9115\n",
            "Epoch: 276, AUC: 0.9081, AP: 0.9115\n",
            "Epoch: 277, AUC: 0.9077, AP: 0.9111\n",
            "Epoch: 278, AUC: 0.9077, AP: 0.9111\n",
            "Epoch: 279, AUC: 0.9087, AP: 0.9119\n",
            "Epoch: 280, AUC: 0.9098, AP: 0.9126\n",
            "Epoch: 281, AUC: 0.9102, AP: 0.9122\n",
            "Epoch: 282, AUC: 0.9103, AP: 0.9121\n",
            "Epoch: 283, AUC: 0.9102, AP: 0.9126\n",
            "Epoch: 284, AUC: 0.9098, AP: 0.9130\n",
            "Epoch: 285, AUC: 0.9105, AP: 0.9143\n",
            "Epoch: 286, AUC: 0.9109, AP: 0.9151\n",
            "Epoch: 287, AUC: 0.9111, AP: 0.9150\n",
            "Epoch: 288, AUC: 0.9115, AP: 0.9152\n",
            "Epoch: 289, AUC: 0.9113, AP: 0.9147\n",
            "Epoch: 290, AUC: 0.9111, AP: 0.9145\n",
            "Epoch: 291, AUC: 0.9107, AP: 0.9144\n",
            "Epoch: 292, AUC: 0.9101, AP: 0.9144\n",
            "Epoch: 293, AUC: 0.9107, AP: 0.9146\n",
            "Epoch: 294, AUC: 0.9119, AP: 0.9153\n",
            "Epoch: 295, AUC: 0.9125, AP: 0.9157\n",
            "Epoch: 296, AUC: 0.9122, AP: 0.9154\n",
            "Epoch: 297, AUC: 0.9114, AP: 0.9151\n",
            "Epoch: 298, AUC: 0.9110, AP: 0.9153\n",
            "Epoch: 299, AUC: 0.9121, AP: 0.9167\n",
            "Epoch: 300, AUC: 0.9135, AP: 0.9173\n",
            "Epoch: 301, AUC: 0.9141, AP: 0.9171\n",
            "Epoch: 302, AUC: 0.9134, AP: 0.9167\n",
            "Epoch: 303, AUC: 0.9132, AP: 0.9173\n",
            "Epoch: 304, AUC: 0.9125, AP: 0.9170\n",
            "Epoch: 305, AUC: 0.9125, AP: 0.9169\n",
            "Epoch: 306, AUC: 0.9134, AP: 0.9174\n",
            "Epoch: 307, AUC: 0.9139, AP: 0.9177\n",
            "Epoch: 308, AUC: 0.9138, AP: 0.9180\n",
            "Epoch: 309, AUC: 0.9133, AP: 0.9178\n",
            "Epoch: 310, AUC: 0.9130, AP: 0.9177\n",
            "Epoch: 311, AUC: 0.9128, AP: 0.9177\n",
            "Epoch: 312, AUC: 0.9126, AP: 0.9169\n",
            "Epoch: 313, AUC: 0.9129, AP: 0.9169\n",
            "Epoch: 314, AUC: 0.9134, AP: 0.9176\n",
            "Epoch: 315, AUC: 0.9133, AP: 0.9179\n",
            "Epoch: 316, AUC: 0.9130, AP: 0.9179\n",
            "Epoch: 317, AUC: 0.9135, AP: 0.9182\n",
            "Epoch: 318, AUC: 0.9133, AP: 0.9175\n",
            "Epoch: 319, AUC: 0.9134, AP: 0.9174\n",
            "Epoch: 320, AUC: 0.9139, AP: 0.9180\n",
            "Epoch: 321, AUC: 0.9139, AP: 0.9180\n",
            "Epoch: 322, AUC: 0.9139, AP: 0.9179\n",
            "Epoch: 323, AUC: 0.9133, AP: 0.9175\n",
            "Epoch: 324, AUC: 0.9130, AP: 0.9172\n",
            "Epoch: 325, AUC: 0.9132, AP: 0.9173\n",
            "Epoch: 326, AUC: 0.9139, AP: 0.9177\n",
            "Epoch: 327, AUC: 0.9141, AP: 0.9179\n",
            "Epoch: 328, AUC: 0.9136, AP: 0.9176\n",
            "Epoch: 329, AUC: 0.9137, AP: 0.9182\n",
            "Epoch: 330, AUC: 0.9139, AP: 0.9182\n",
            "Epoch: 331, AUC: 0.9145, AP: 0.9185\n",
            "Epoch: 332, AUC: 0.9153, AP: 0.9191\n",
            "Epoch: 333, AUC: 0.9151, AP: 0.9187\n",
            "Epoch: 334, AUC: 0.9150, AP: 0.9189\n",
            "Epoch: 335, AUC: 0.9141, AP: 0.9182\n",
            "Epoch: 336, AUC: 0.9133, AP: 0.9177\n",
            "Epoch: 337, AUC: 0.9144, AP: 0.9186\n",
            "Epoch: 338, AUC: 0.9159, AP: 0.9195\n",
            "Epoch: 339, AUC: 0.9164, AP: 0.9193\n",
            "Epoch: 340, AUC: 0.9160, AP: 0.9188\n",
            "Epoch: 341, AUC: 0.9151, AP: 0.9184\n",
            "Epoch: 342, AUC: 0.9140, AP: 0.9175\n",
            "Epoch: 343, AUC: 0.9145, AP: 0.9185\n",
            "Epoch: 344, AUC: 0.9159, AP: 0.9197\n",
            "Epoch: 345, AUC: 0.9164, AP: 0.9204\n",
            "Epoch: 346, AUC: 0.9162, AP: 0.9202\n",
            "Epoch: 347, AUC: 0.9155, AP: 0.9198\n",
            "Epoch: 348, AUC: 0.9146, AP: 0.9193\n",
            "Epoch: 349, AUC: 0.9143, AP: 0.9190\n",
            "Epoch: 350, AUC: 0.9147, AP: 0.9195\n",
            "Epoch: 351, AUC: 0.9157, AP: 0.9203\n",
            "Epoch: 352, AUC: 0.9161, AP: 0.9200\n",
            "Epoch: 353, AUC: 0.9160, AP: 0.9201\n",
            "Epoch: 354, AUC: 0.9151, AP: 0.9197\n",
            "Epoch: 355, AUC: 0.9145, AP: 0.9193\n",
            "Epoch: 356, AUC: 0.9152, AP: 0.9199\n",
            "Epoch: 357, AUC: 0.9159, AP: 0.9201\n",
            "Epoch: 358, AUC: 0.9167, AP: 0.9201\n",
            "Epoch: 359, AUC: 0.9168, AP: 0.9201\n",
            "Epoch: 360, AUC: 0.9167, AP: 0.9206\n",
            "Epoch: 361, AUC: 0.9159, AP: 0.9202\n",
            "Epoch: 362, AUC: 0.9161, AP: 0.9204\n",
            "Epoch: 363, AUC: 0.9169, AP: 0.9204\n",
            "Epoch: 364, AUC: 0.9174, AP: 0.9200\n",
            "Epoch: 365, AUC: 0.9179, AP: 0.9205\n",
            "Epoch: 366, AUC: 0.9181, AP: 0.9215\n",
            "Epoch: 367, AUC: 0.9174, AP: 0.9212\n",
            "Epoch: 368, AUC: 0.9172, AP: 0.9210\n",
            "Epoch: 369, AUC: 0.9173, AP: 0.9204\n",
            "Epoch: 370, AUC: 0.9181, AP: 0.9207\n",
            "Epoch: 371, AUC: 0.9186, AP: 0.9209\n",
            "Epoch: 372, AUC: 0.9182, AP: 0.9207\n",
            "Epoch: 373, AUC: 0.9183, AP: 0.9215\n",
            "Epoch: 374, AUC: 0.9188, AP: 0.9224\n",
            "Epoch: 375, AUC: 0.9196, AP: 0.9230\n",
            "Epoch: 376, AUC: 0.9202, AP: 0.9232\n",
            "Epoch: 377, AUC: 0.9202, AP: 0.9228\n",
            "Epoch: 378, AUC: 0.9194, AP: 0.9219\n",
            "Epoch: 379, AUC: 0.9192, AP: 0.9218\n",
            "Epoch: 380, AUC: 0.9198, AP: 0.9227\n",
            "Epoch: 381, AUC: 0.9207, AP: 0.9239\n",
            "Epoch: 382, AUC: 0.9209, AP: 0.9242\n",
            "Epoch: 383, AUC: 0.9207, AP: 0.9239\n",
            "Epoch: 384, AUC: 0.9206, AP: 0.9233\n",
            "Epoch: 385, AUC: 0.9204, AP: 0.9227\n",
            "Epoch: 386, AUC: 0.9201, AP: 0.9223\n",
            "Epoch: 387, AUC: 0.9200, AP: 0.9227\n",
            "Epoch: 388, AUC: 0.9199, AP: 0.9232\n",
            "Epoch: 389, AUC: 0.9204, AP: 0.9237\n",
            "Epoch: 390, AUC: 0.9205, AP: 0.9238\n",
            "Epoch: 391, AUC: 0.9203, AP: 0.9234\n",
            "Epoch: 392, AUC: 0.9202, AP: 0.9229\n",
            "Epoch: 393, AUC: 0.9202, AP: 0.9228\n",
            "Epoch: 394, AUC: 0.9202, AP: 0.9230\n",
            "Epoch: 395, AUC: 0.9207, AP: 0.9237\n",
            "Epoch: 396, AUC: 0.9207, AP: 0.9239\n",
            "Epoch: 397, AUC: 0.9206, AP: 0.9240\n",
            "Epoch: 398, AUC: 0.9206, AP: 0.9238\n",
            "Epoch: 399, AUC: 0.9204, AP: 0.9234\n",
            "Epoch: 400, AUC: 0.9201, AP: 0.9228\n",
            "Median time per epoch: 0.0544s\n"
          ]
        }
      ]
    }
  ]
}